from dotenv import load_dotenv
from scripts.query_processing import process_user_input
from scripts.retrieval import retrieve_top_k
from llm.llm_connect import LLMConnector
from scripts.prompt_template import create_prompt
import sys
import os

# **è¼‰å…¥ç’°å¢ƒè®Šæ•¸**
load_dotenv()

# **åˆå§‹åŒ– LLMConnector**
llm = LLMConnector(model="gpt-4", temperature=0.7)

# **ç²å–ç”¨æˆ¶è¼¸å…¥**
user_input = input("è«‹è¼¸å…¥ä½ çš„æ„Ÿæƒ…å•é¡Œï¼š")
processed_input = process_user_input(user_input)

# **åŸ·è¡Œ RAG æª¢ç´¢**
chat_history = retrieve_top_k(processed_input["query"], "chat_history")
relationship_analysis = retrieve_top_k(processed_input["query"], "relationship_analysis")
strategy_analysis = retrieve_top_k(processed_input["query"], "strategy_analysis")

# **æ‰“å°æª¢ç´¢çµæœ**
print("\nğŸ” **æª¢ç´¢åˆ°çš„å…§å®¹**:")
print(f"\nğŸ“œ **Chat History (å°è©±è¨˜éŒ„)**: {chat_history}")
print(f"\nğŸ“– **Relationship Analysis (é—œä¿‚åˆ†æ)**: {relationship_analysis}")
print(f"\nğŸ§  **Strategy Analysis (ç­–ç•¥åˆ†æ)**: {strategy_analysis}")

# **æª¢æŸ¥ Qdrant æ˜¯å¦è¿”å›çµæœ**
if not chat_history and not relationship_analysis and not strategy_analysis:
    print("âš ï¸ Qdrant æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™ï¼Œè«‹ç¢ºèªæ•¸æ“šæ˜¯å¦æ­£ç¢ºå­˜å…¥ã€‚")
    exit()

# **çµ„åˆ Prompt**
final_prompt = create_prompt(
    processed_input["query"], chat_history, relationship_analysis, strategy_analysis
)

# **æ‰“å°å‚³éçµ¦ Prompt Template çš„å…§å®¹**
print("\nğŸ“ **å‚³éçµ¦ `create_prompt` çš„å…§å®¹**:")
print(final_prompt)

# **è©¢å• GPT-4**
response = llm.generate_response(final_prompt)

# **æ‰“å° AI ç”Ÿæˆçš„å›æ‡‰**
print("\nğŸ¤– **AI ç”Ÿæˆçš„å›æ‡‰**:")
print(response)
